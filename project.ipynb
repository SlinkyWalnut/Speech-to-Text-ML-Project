{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5b5f90",
   "metadata": {},
   "source": [
    "Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d187ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of waveform: torch.Size([1, 16000])\n",
      "Label: backward\n",
      "Sample Rate: 16000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(\"./\", download=True)\n",
    "        \n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as fileobj:\n",
    "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
    "\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "\n",
    "train_set = SubsetSC(\"training\")\n",
    "test_set = SubsetSC(\"testing\")\n",
    "\n",
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]\n",
    "\n",
    "print(f\"Shape of waveform: {waveform.size()}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Sample Rate: {sample_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25afa72d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e88af28b",
   "metadata": {},
   "source": [
    "For the recognition, we will try to just recognize what a word looks like using a convolutional neural network. So we can transform the audio from raw audio into a 2d spectogram then input that into the cnn. Additionally, for shorter words, the cnn can find the word shape wherever it is in the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc009f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  torch.Size([1, 64, 81])\n"
     ]
    }
   ],
   "source": [
    "transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_mels=64\n",
    ")\n",
    "spectrogram = transform(waveform)\n",
    "print(\"Shape: \", spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb53b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e310f942",
   "metadata": {},
   "source": [
    "Showing what a spectogram looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "71c29ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3941825d0>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.plot(spectrogram[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbff910",
   "metadata": {},
   "source": [
    "Making labels for training. ready_data function is used to standardize the data and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "276195f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(list(set(datapoint[2] for datapoint in train_set)))\n",
    "label_to_index = {label: index for index, label in enumerate(labels)}\n",
    "def ready_data(batch):\n",
    "    #A batch is a list of objects in the train set\n",
    "    tensors, targets = [],[]\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        tensors += [waveform.squeeze(0)]\n",
    "        targets += [label_to_index[label]]\n",
    "    # makes all samples the same size\n",
    "    tensors = torch.nn.utils.rnn.pad_sequence(tensors, batch_first=True)\n",
    "\n",
    "    #makes targets into single tensor\n",
    "    targets = torch.stack([torch.tensor(t) for t in targets])\n",
    "    return tensors, targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b9137176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backward', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'follow', 'forward', 'four', 'go', 'happy', 'house', 'learn', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'visual', 'wow', 'yes', 'zero']\n",
      "backward\n",
      "35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(set(labels))\n",
    "print(labels)\n",
    "print(train_set[4][2])\n",
    "print(num_labels)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f619ac",
   "metadata": {},
   "source": [
    "Using the cnn we used for homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "70593f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "699b609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bolajialabi/Projects/MLenv/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/bolajialabi/Projects/MLenv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877bbd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2dNormActivation(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6(inplace=True)\n",
       "  )\n",
       "  (1): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (2): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (3): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (4): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (9): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (10): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (11): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (12): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (13): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (14): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (15): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (16): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (17): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (18): Conv2dNormActivation(\n",
       "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e4f66",
   "metadata": {},
   "source": [
    "Im training using my mac so this is for using mac gpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1982ca18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found. Using MPS.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS device found. Using MPS.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347360a",
   "metadata": {},
   "source": [
    "training preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f6ce2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n"
     ]
    }
   ],
   "source": [
    "num_features = model.features[-1].out_channels\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7c47e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    collate_fn=ready_data,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set, \n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    collate_fn=ready_data,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "num_hidden = 100\n",
    "\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "nn.Dropout(0.2),\n",
    "nn.Linear(in_features=num_features, out_features=num_hidden),\n",
    "nn.ReLU(),\n",
    "nn.Linear(in_features=num_hidden, out_features=num_labels)\n",
    ")\n",
    "# Making process run on gpu\n",
    "model = model.to(device)\n",
    "\n",
    "transform = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=64).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b850a6a",
   "metadata": {},
   "source": [
    "Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ac31e148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|| 2652/2652 [06:38<00:00,  6.65it/s, loss=0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 2871.2212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 344/344 [00:38<00:00,  8.98it/s, Accuracy=80.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Test Accuracy: 80.46%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 2652/2652 [06:42<00:00,  6.59it/s, loss=0.406] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 1319.7003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 344/344 [00:37<00:00,  9.12it/s, Accuracy=70.89%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Test Accuracy: 70.89%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|| 2652/2652 [06:30<00:00,  6.79it/s, loss=0.393] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 995.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 344/344 [00:35<00:00,  9.80it/s, Accuracy=75.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Test Accuracy: 75.61%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|| 2652/2652 [06:27<00:00,  6.85it/s, loss=0.154] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 810.4070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 344/344 [00:36<00:00,  9.48it/s, Accuracy=76.56%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Test Accuracy: 76.56%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|| 2652/2652 [06:19<00:00,  6.99it/s, loss=0.617] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 688.1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 344/344 [00:35<00:00,  9.56it/s, Accuracy=76.29%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Test Accuracy: 76.29%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nepochs = 5\n",
    "for epoch in range(nepochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=True)\n",
    "    for images, targets in loop:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        #making image 3d to match rgb\n",
    "        spectrogram = transform(images)\n",
    "        spectrogram = spectrogram.unsqueeze(1)\n",
    "        spectrogram = spectrogram.repeat(1,3,1,1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(spectrogram)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {running_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(test_loader, desc=\"Evaluating\", leave=True)\n",
    "        for images, targets in loop:\n",
    "\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            spectrogram = transform(images)\n",
    "            spectrogram = spectrogram.unsqueeze(1)\n",
    "            spectrogram = spectrogram.repeat(1,3,1,1)\n",
    "            outputs = model(spectrogram)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct / total \n",
    "            loop.set_postfix({'Accuracy': f'{accuracy:.2f}%'})\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}, Test Accuracy: {accuracy:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9a86532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "def predict_single_file(filepath, model, transform, class_names, device):\n",
    "    waveform, sample_rate = torchaudio.load(filepath)\n",
    "    \n",
    "    if sample_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform).to(device)\n",
    "\n",
    "    spectrogram = transform(waveform)\n",
    "    spectrogram = spectrogram.unsqueeze(0) \n",
    "\n",
    "    # 4. Move to device\n",
    "    spectrogram = spectrogram.to(device)\n",
    "    spectrogram = spectrogram.repeat(1,3,1,1)\n",
    "\n",
    "    # 5. Predict\n",
    "    model.eval() # Switch to eval mode (turns off dropout, etc.)\n",
    "    with torch.no_grad():\n",
    "        output = model(spectrogram)\n",
    "        \n",
    "        # Get the class with the highest score\n",
    "        prediction_index = output.argmax(dim=1).item()\n",
    "        predicted_label = class_names[prediction_index]\n",
    "        confidence = output.softmax(dim=1).max().item()\n",
    "\n",
    "    return predicted_label, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "702657c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: happy\n",
      "Confidence: 100.00%\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "wav_file_path = \"batHappy.wav\" # Replace this with your file path\n",
    "\n",
    "prediction, conf = predict_single_file(\n",
    "    wav_file_path, \n",
    "    model, \n",
    "    transform, \n",
    "    labels, \n",
    "    device\n",
    ")\n",
    "\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Confidence: {conf * 100:.2f}%\")\n",
    "print(label_to_index[\"happy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d04f94",
   "metadata": {},
   "source": [
    "Next, I will try a 1D CNN that is better accustomed for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff03ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as ready data command but for 1D data\n",
    "def ready_data_array(batch):\n",
    "    batch = [item for item in batch]\n",
    "    tensors = [item[0].permute(1,0) for item in batch]\n",
    "    tensors = torch.nn.utils.rnn.pad_sequence(tensors, batch_first=True)\n",
    "    tensors = tensors.permute(0, 2, 1)\n",
    "\n",
    "    targets = torch.tensor([label_to_index[item[2]] for item in batch])\n",
    "\n",
    "    return tensors, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "358383db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Data Loader\n",
    "batch_size = 256\n",
    "\n",
    "train_loader2 = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True, collate_fn=ready_data_array, num_workers=0\n",
    ")\n",
    "\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=batch_size, shuffle=False, collate_fn=ready_data_array, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5acb7",
   "metadata": {},
   "source": [
    "I will be using the M5 model for this. It appears that M5 is known for processing raw audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec6ad129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # Block 1\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "\n",
    "        # Block 2\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "\n",
    "        # Block 3\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 *n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2*n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "\n",
    "        #Block 4\n",
    "        self.conv4 = nn.Conv1d(2*n_channel, 2 *n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2*n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        \n",
    "        #Output Layer\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4af18118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M5(\n",
       "  (conv1): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=29, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model declaration\n",
    "model2 = M5(n_input=1, n_output=len(labels))\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98820816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|| 332/332 [04:19<00:00,  1.28it/s, loss=0.0774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 75.6278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 43/43 [00:30<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Test Accuracy: 72.89%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 332/332 [04:03<00:00,  1.36it/s, loss=0.451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 72.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 43/43 [00:29<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Test Accuracy: 73.03%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|| 332/332 [04:06<00:00,  1.35it/s, loss=0.183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 70.8363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 43/43 [00:30<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Test Accuracy: 72.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|| 332/332 [04:14<00:00,  1.30it/s, loss=0.0968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 69.4152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 43/43 [00:31<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Test Accuracy: 73.15%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|| 332/332 [04:12<00:00,  1.31it/s, loss=0.266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 67.7568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 43/43 [00:32<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Test Accuracy: 72.98%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler2 = optim.lr_scheduler.StepLR(optimizer2, step_size=20, gamma= 0.1)\n",
    "\n",
    "log_i = 20\n",
    "\n",
    "for epoch in range(1, nepochs+ 1):\n",
    "    model2.train()\n",
    "    running_loss = 0.0\n",
    "    loop = tqdm(train_loader2, desc=f\"Epoch {epoch}\", leave=True)\n",
    "    for sound, target in loop:\n",
    "        sound = sound.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "        output = model2(sound)\n",
    "\n",
    "        output = output.squeeze()\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    print(f\"Epoch {epoch}, Training Loss: {running_loss:.4f}\")\n",
    "\n",
    "    model2.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(test_loader2, desc=\"Evaluating\", leave=True)\n",
    "        for sound, target in loop:\n",
    "            sound = sound.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model2(sound)\n",
    "            output = output.squeeze()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = 100. * correct / len(test_loader.dataset)\n",
    "    print(f\"Epoch {epoch}, Test Accuracy: {acc:.2f}%\\n\")\n",
    "    scheduler2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e5680ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_file2(model, file_path, labels, device):\n",
    "    model.eval()\n",
    "\n",
    "    waveform, sample_rate= torchaudio.load(file_path)\n",
    "    if sample_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform).to(device)\n",
    "    \n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "    if waveform.shape[1] < 16000:\n",
    "        # Pad with zeros\n",
    "        padding = 16000 - waveform.shape[1]\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "    elif waveform.shape[1] > 16000:\n",
    "        waveform = waveform[:, :16000]\n",
    "    \n",
    "    input_tensor = waveform.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        output = output.squeeze()\n",
    "\n",
    "        probability = torch.exp(output)\n",
    "        top_p, top_class = probability.topk(1, dim=0)\n",
    "    prediction = labels[top_class.item()]\n",
    "    confidence = top_p.item()\n",
    "    return prediction, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7a961f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: happy\n",
      "Confidence: 100.00%\n",
      "Correct class: 12\n"
     ]
    }
   ],
   "source": [
    "wav_file_path = \"batHappy.wav\"\n",
    "\n",
    "prediction, conf = predict_single_file2(model2, wav_file_path, labels, device)\n",
    "\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Confidence: {conf*100:.2f}%\")\n",
    "print(f\"Correct class: {label_to_index[\"happy\"]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa44a6f0",
   "metadata": {},
   "source": [
    "Finally I will try to use an RNN for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "35959d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bolajialabi/Projects/MLenv/lib/python3.13/site-packages/torchaudio/functional/functional.py:582: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "\n",
    "# Using Mel-Frequency Cepstral Coefficients to generate features that will be engineered using RNN\n",
    "mfcc_transform = torchaudio.transforms.MFCC(\n",
    "    sample_rate=16000,\n",
    "    n_mfcc=40  # 40 features per time step\n",
    ").to(device)\n",
    "\n",
    "def ready_data3(batch):\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    for waveform, _, label, _, _ in batch:\n",
    "        target = label_to_index[label]\n",
    "        \n",
    "        if waveform.shape[1] < 16000:\n",
    "            pad_amount = 16000 - waveform.shape[1]\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, pad_amount))\n",
    "        else:\n",
    "            waveform = waveform[:, :16000]\n",
    "        \n",
    "        tensors.append(waveform)\n",
    "        target.append(label)\n",
    "\n",
    "    tensors = torch.stack(tensors).to(device)\n",
    "    targets = torch.tensor(targets).to(device)\n",
    "\n",
    "    mfcc = mfcc_transform(tensors).squeeze(1)\n",
    "\n",
    "    mfcc = mfcc.transpose(1,2)\n",
    "\n",
    "    return mfcc, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3e64a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading again\n",
    "train_loader3 = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True, collate_fn=ready_data3, num_workers=0\n",
    ")\n",
    "\n",
    "test_loader3 = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=batch_size, shuffle=False, collate_fn=ready_data3, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149344d",
   "metadata": {},
   "source": [
    "Using Long Short Term Memory (LSTM) as recurrent neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a52eb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = layers\n",
    "\n",
    "        #LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layers, batch_first=True, dropout=0.3)\n",
    "\n",
    "        # Fully Connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layers, x.size(0), self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.layers, x.size(0), self.hidden_dim).to(device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f7c5323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model initiation\n",
    "model3 = LSTM(input_dim=40, hidden_dim=128, output_dim=len(labels)).to(device)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=LR)\n",
    "criterion3 = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aeec04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/332 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[116]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m      7\u001b[39m loop = tqdm(train_loader3, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/MLenv/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/MLenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/MLenv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/MLenv/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mready_data3\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m     20\u001b[39m         waveform = waveform[:, :\u001b[32m16000\u001b[39m]\n\u001b[32m     22\u001b[39m     tensors.append(waveform)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m(label)\n\u001b[32m     25\u001b[39m tensors = torch.stack(tensors).to(device)\n\u001b[32m     26\u001b[39m targets = torch.tensor(targets).to(device)\n",
      "\u001b[31mAttributeError\u001b[39m: 'int' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# Training ... again\n",
    "for epoch in range(nepochs):\n",
    "    model3.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    loop = tqdm(train_loader3, desc=f\"Epoch {epoch}\", leave=True)\n",
    "    for data, target in loop:\n",
    "        optimizer3.zero_grad()\n",
    "        output = model3(data)\n",
    "        \n",
    "        loss = criterion3(output, target)\n",
    "        loss.backward()\n",
    "        optimizer3.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    print(f\"Epoch {epoch}, Training Loss: {running_loss:.4f}\")\n",
    "    model3.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(test_loader3, desc=\"Evaluating\", leave=True)\n",
    "        for data, target in loop:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model3(data)\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "            count += len(data)\n",
    "        acc = 100. * correct / count\n",
    "        print(f\"Epoch {epoch}, Test Accuracy: {acc:.2f}%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
